{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training a CNN on MINST dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MassimilianoBiancucci/Tensorflow-exercises/blob/master/CNNs/Training_a_CNN_on_MINST_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "JWoJ4cv77Rbd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training a CNN on MINST dataset"
      ]
    },
    {
      "metadata": {
        "id": "l2ZBudqz17Kh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this section we download the packets needed for run a tensorboard remotly on colab and get a link at ngrok.com to access to the tensorboard trought the colab's firewall.\n",
        "![alt text](https://gitcdn.xyz/cdn/Tony607/blog_statics/d425c3fe4cf0d92067572e25ae6cc3198d51936b//images/ngrok/ngrok.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "X73uV25F08pr",
        "colab_type": "code",
        "outputId": "54b4518b-2f10-4b89-bb05-fcb57a62cfce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!rm /content/ngrok\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-23 19:59:47--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.204.136.9, 34.206.253.53, 54.174.228.92, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.204.136.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14977695 (14M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.16’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  58%[==========>         ]   8.37M  41.4MB/s               \rngrok-stable-linux- 100%[===================>]  14.28M  58.3MB/s    in 0.2s    \n",
            "\n",
            "2019-04-23 19:59:48 (58.3 MB/s) - ‘ngrok-stable-linux-amd64.zip.16’ saved [14977695/14977695]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z5rXtmcd17iv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "here we launch the tensorboard in background and  set the directory for saving session log.\n"
      ]
    },
    {
      "metadata": {
        "id": "iMyAOfmG09cR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KssEpVBS2GwZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then, we can run ngrok to tunnel TensorBoard port 6006 to the outside world. This command also runs in the background.\n"
      ]
    },
    {
      "metadata": {
        "id": "dzJYm_O12zKu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jGQdt_OC2zvi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we get the public URL where we can access the colab TensorBoard.\n",
        "It's important keep in mind that the training have to start before you can see somthing in. \n"
      ]
    },
    {
      "metadata": {
        "id": "MBPAVeUu2OH1",
        "colab_type": "code",
        "outputId": "7fc73b43-36e5-4adb-9878-4154aadad704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://d0faa220.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AvXMFX_tW_We",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "ctwP8xnh7Euk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r ./log/train\n",
        "!rm -r ./log/test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-aXMYstM7FPq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "SXwmERwLHBUT",
        "colab_type": "code",
        "outputId": "e8ec4fa9-d87b-4947-841b-5768e0843b77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j--IhtL4T648",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "S7end1BaT7Qw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
        "\n",
        "input_size = 784\n",
        "no_classes = 10\n",
        "batch_size = 100\n",
        "total_batches = 200\n",
        "iter_no = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xYTJXGVUT-fr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Bf-lwrWqT-8A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_input = tf.placeholder(tf.float32, shape=[None, input_size])\n",
        "y_input = tf.placeholder(tf.float32, shape=[None, no_classes])\n",
        "keep_prob = tf.placeholder(tf.float32) #dropuot keep_prob placeholder\n",
        "\n",
        "x_input_reshape = tf.reshape(x_input, [-1, 28, 28, 1], name='input_reshape')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sTSOkcnPUB9I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "t2cD9TX5UCZg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_variable_summary(tf_variable, summary_name):\n",
        "  with tf.name_scope(summary_name + '_summary'):\n",
        "    mean = tf.reduce_mean(tf_variable)\n",
        "    tf.summary.scalar('Mean', mean)\n",
        "    with tf.name_scope('standard_deviation'):\n",
        "        standard_deviation = tf.sqrt(tf.reduce_mean(\n",
        "            tf.square(tf_variable - mean)))\n",
        "    tf.summary.scalar('StandardDeviation', standard_deviation)\n",
        "    tf.summary.scalar('Maximum', tf.reduce_max(tf_variable))\n",
        "    tf.summary.scalar('Minimum', tf.reduce_min(tf_variable))\n",
        "    tf.summary.histogram('Histogram', tf_variable)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K_rg--27UPU8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "ZeDgpxMzUPrx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convolution_layer(input_layer, filters, kernel_size=[5, 5], activation=tf.nn.relu):\n",
        "    with tf.device('/gpu:0'):  \n",
        "        layer = tf.layers.conv2d(\n",
        "            inputs=input_layer,\n",
        "            filters=filters,\n",
        "            kernel_size=kernel_size,\n",
        "            activation=activation\n",
        "        )\n",
        "    add_variable_summary(layer, 'convolution')\n",
        "    return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LmxcbaWtUW4d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "DCMoSiwHUXTT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pooling_layer(input_layer, pool_size=[2, 2], strides=2):\n",
        "    with tf.device('/gpu:0'):  \n",
        "      layer = tf.layers.max_pooling2d(\n",
        "          inputs=input_layer,\n",
        "          pool_size=pool_size,\n",
        "          strides=strides\n",
        "      )\n",
        "    add_variable_summary(layer, 'pooling')\n",
        "    return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sfg71mRAUfn8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "s73UqZtTUf80",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dense_layer(input_layer, units, activation=tf.nn.relu):\n",
        "   with tf.device('/gpu:0'):    \n",
        "      layer = tf.layers.dense(\n",
        "                                inputs=input_layer,\n",
        "                                units=units,\n",
        "                                activation=activation\n",
        "                             )\n",
        "   add_variable_summary(layer, 'dense')\n",
        "   return layer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kiSrpQfPU5iR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "_4a4A8mBU6F9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "convolution_layer_1 = convolution_layer(x_input_reshape, 64)\n",
        "pooling_layer_1 = pooling_layer(convolution_layer_1)\n",
        "convolution_layer_2 = convolution_layer(pooling_layer_1, 128)\n",
        "pooling_layer_2 = pooling_layer(convolution_layer_2)\n",
        "flattened_pool = tf.reshape(pooling_layer_2, [-1, 4 * 4 * 128],\n",
        "                            name='flattened_pool')\n",
        "dense_layer_bottleneck = dense_layer(flattened_pool, 1024)\n",
        "with tf.device('/gpu:0'):\n",
        "    dropout_layer = tf.layers.dropout(\n",
        "            inputs=dense_layer_bottleneck,\n",
        "            rate = 1 - keep_prob,\n",
        "        )\n",
        "logits = dense_layer(dropout_layer, no_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5od2_c6yU_ud",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "nopJV9raVALh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope('loss'):\n",
        "    with tf.device('/gpu:0'):\n",
        "      softmax_cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "          labels=y_input, logits=logits)\n",
        "      loss_operation = tf.reduce_mean(softmax_cross_entropy, name='loss')\n",
        "    tf.summary.scalar('loss', loss_operation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lIUJ3USvVFix",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "6IcNTZvIVF8o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope('optimiser'):\n",
        "  with tf.device('/gpu:0'):\n",
        "     optimiser = tf.train.AdagradOptimizer(learning_rate=0.02).minimize(loss_operation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6-BRZ-UTVHuW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "GidzOwzEVIC7",
        "colab_type": "code",
        "outputId": "64196f17-6486-4048-fa3d-2344b94d6b89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope('accuracy'):\n",
        "    with tf.name_scope('correct_prediction'):\n",
        "      with tf.device('/gpu:0'):\n",
        "        predictions = tf.argmax(logits, 1)\n",
        "        correct_predictions = tf.equal(predictions, tf.argmax(y_input, 1))\n",
        "    with tf.name_scope('accuracy'):\n",
        "      with tf.device('/gpu:0'):\n",
        "        accuracy_operation = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
        "tf.summary.scalar('accuracy', accuracy_operation)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'accuracy_1:0' shape=() dtype=string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "a4A10gf4VKgv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "iE8huWkmVK8F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "session = tf.Session(config = config)\n",
        "session.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7u4-ifLeVO8l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "i0BYvjB4VPRw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "merged_summary_operation = tf.summary.merge_all()\n",
        "train_summary_writer = tf.summary.FileWriter('./log/train', session.graph)\n",
        "test_summary_writer = tf.summary.FileWriter('./log/test')\n",
        "\n",
        "test_images, test_labels = mnist_data.test.images, mnist_data.test.labels\n",
        "#valid_images, valid_labels = mnist_data. # , mnist_data."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qr_r_PGsVVly",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "0Sxj6nefVV3m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for iterN in range(iter_no):\n",
        "  for batch_no in range(total_batches):\n",
        "      print(\"iter: \" + str(iterN) + \" - batch: \" + str(batch_no) + \"/\" + str(total_batches))\n",
        "      mnist_batch = mnist_data.train.next_batch(batch_size)\n",
        "      train_images, train_labels = mnist_batch[0], mnist_batch[1]\n",
        "      _, merged_summary = session.run([optimiser, merged_summary_operation],\n",
        "                                      feed_dict={\n",
        "                                                  x_input: train_images,\n",
        "                                                  y_input: train_labels,\n",
        "                                                  keep_prob : 1.0\n",
        "                                                 })\n",
        "      train_summary_writer.add_summary(merged_summary, (batch_no + (iterN*200)))\n",
        "      if (batch_no + (iterN*200)) % 500 == 0:\n",
        "          merged_summary, _ = session.run([merged_summary_operation,\n",
        "                                           accuracy_operation], feed_dict={\n",
        "                                                                            x_input: test_images,\n",
        "                                                                            y_input: test_labels,\n",
        "                                                                            keep_prob: 1.0\n",
        "                                                                        })\n",
        "          test_summary_writer.add_summary(merged_summary, (batch_no + (iterN*200)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}